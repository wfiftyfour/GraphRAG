# Giáº£i thÃ­ch chi tiáº¿t vá» Metrics

## TÃ³m táº¯t nhanh

Khi so sÃ¡nh Traditional RAG vs GraphRAG, cÃ³ 4 metrics Ä‘o lÆ°á»ng **4 khÃ­a cáº¡nh hoÃ n toÃ n khÃ¡c nhau**:

| Metric | Äo lÆ°á»ng gÃ¬ | Táº¡i sao quan trá»ng |
|--------|-------------|-------------------|
| **Relevance** | Query vÃ  results cÃ³ liÃªn quan khÃ´ng? | Náº¿u retrieve sai â†’ answer sai |
| **Coverage** | Information cÃ³ Ä‘a dáº¡ng khÃ´ng? | Nhiá»u gÃ³c nhÃ¬n â†’ answer toÃ n diá»‡n hÆ¡n |
| **Quality** | Answer cÃ³ hay khÃ´ng? | LLM cÃ³ generate tá»‘t khÃ´ng? |
| **Faithfulness** | Answer cÃ³ trung thá»±c vá»›i context khÃ´ng? | TrÃ¡nh hallucination/bá»‹a Ä‘áº·t |

---

## 1. Relevance Score (0-1)

### Äo lÆ°á»ng: Äá»™ liÃªn quan giá»¯a query vÃ  retrieved results

**CÃ´ng thá»©c:**
```
relevance = 0.7 Ã— similarity_score + 0.3 Ã— token_overlap
```

**VÃ­ dá»¥:**
```
Query: "What supplements for males?"
Result: "Adult males need vitamin D supplements for bone health"

â€¢ Similarity score (tá»« vector search): 0.85
â€¢ Token overlap: {supplements, males} / {supplements, for, males} = 2/3 = 0.67
â€¢ Relevance = 0.7 Ã— 0.85 + 0.3 Ã— 0.67 = 0.80
```

**Táº¡i sao khÃ¡c nhau?**
- **Traditional RAG**: Vector search trÃªn chunks â†’ tá»‘t cho exact matches
- **GraphRAG Local**: Vector search + graph context â†’ tá»‘t cho related concepts
- **GraphRAG Global**: Search communities â†’ tá»‘t cho broad topics

---

## 2. Coverage Score (0-1) â­ QUAN TRá»ŒNG NHáº¤T

### Äo lÆ°á»ng: Äá»™ Ä‘a dáº¡ng vÃ  toÃ n diá»‡n cá»§a information

**CÃ´ng thá»©c (3 thÃ nh pháº§n):**
```
coverage = 0.4 Ã— entity_diversity + 0.3 Ã— content_diversity + 0.3 Ã— type_diversity
```

### A. Entity Diversity (40% weight) - ÄÃ‚Y LÃ€ KEY!

**Äáº¿m sá»‘ entities duy nháº¥t trong results:**
```python
entity_diversity = unique_entities / (num_results Ã— 2)

# VÃ­ dá»¥:
# 5 results, 8 entities unique â†’ 8/(5Ã—2) = 0.8
```

**Táº I SAO GRAPHRAG COVERAGE CAO HÆ N RAG:**

**Traditional RAG:**
```
â€¢ Chunks khÃ´ng cÃ³ entity metadata
â€¢ entity_diversity = 0/30 = 0.0
â€¢ Contribution: 0.4 Ã— 0.0 = 0.00  âŒ
```

**GraphRAG Global:**
```
â€¢ Extract entities tá»« community titles
â€¢ Example: "body weight, adult males, and 79 others"
  â†’ entities = ["body weight", "adult males"]
â€¢ 5 communities Ã— 2 entities avg = 10 entities
â€¢ entity_diversity = 10/(5Ã—2) = 1.0
â€¢ Contribution: 0.4 Ã— 1.0 = 0.40  âœ…
```

**ÄÃ‚Y LÃ€ LÃ DO CHÃNH Táº I SAO:**
- Traditional RAG coverage â‰ˆ 0.1-0.3
- GraphRAG Global coverage â‰ˆ 0.5-0.7

### B. Content Diversity (30% weight)

**Äo overlap giá»¯a ná»™i dung cÃ¡c results:**
```python
# So sÃ¡nh tá»«ng cáº·p results
# Overlap cao â†’ diversity tháº¥p (ná»™i dung láº·p láº¡i)

Result 1: "protein intake for males"
Result 2: "protein requirements males"  â†’ overlap = 0.8 (giá»‘ng nhau)
Result 3: "calcium supplements bones"  â†’ overlap = 0.2 (khÃ¡c biá»‡t)

avg_overlap = (0.8 + 0.2) / 2 = 0.5
content_diversity = 1.0 - 0.5 = 0.5
```

### C. Type Diversity (30% weight)

**Äáº¿m sá»‘ loáº¡i results:**
```
type_diversity = num_types / 3  (expect tá»‘i Ä‘a 3 types)

â€¢ Traditional RAG: chá»‰ 'chunk' â†’ 1/3 = 0.33
â€¢ GraphRAG Local: 'chunk' + 'entity' â†’ 2/3 = 0.67
â€¢ GraphRAG Global: chá»‰ 'community' â†’ 1/3 = 0.33
```

### VÃ­ dá»¥ tÃ­nh Coverage Ä‘áº§y Ä‘á»§:

**Traditional RAG:**
```
entity_diversity   = 0.0  â†’ 0.4 Ã— 0.0  = 0.00
content_diversity  = 0.6  â†’ 0.3 Ã— 0.6  = 0.18
type_diversity     = 0.33 â†’ 0.3 Ã— 0.33 = 0.10
                             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
coverage =                      0.28
```

**GraphRAG Global:**
```
entity_diversity   = 0.8  â†’ 0.4 Ã— 0.8  = 0.32  â­
content_diversity  = 0.7  â†’ 0.3 Ã— 0.7  = 0.21
type_diversity     = 0.33 â†’ 0.3 Ã— 0.33 = 0.10
                             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
coverage =                      0.63
```

---

## 3. Answer Quality (0-1)

### Äo lÆ°á»ng: Cháº¥t lÆ°á»£ng cá»§a cÃ¢u tráº£ lá»i

**CÃ´ng thá»©c (3 thÃ nh pháº§n):**

### A. Completeness - Answer cÃ³ address query khÃ´ng?
```
query_coverage = (query_tokens âˆ© answer_tokens) / query_tokens

Query:  "What supplements for males?"
Answer: "Males should take vitamin D supplements..."
Common: {supplements, males} = 2
Query:  {supplements, for, males} = 3
completeness = 2/3 = 0.67
```

### B. Informativeness - Äá»™ dÃ i há»£p lÃ½
```
â€¢ < 50 words:   too short â†’ score = word_count/50
â€¢ 100-500 words: optimal â†’ score = 1.0
â€¢ > 500 words:   too long â†’ score giáº£m dáº§n

Example:
â€¢ 30 words  â†’ 30/50 = 0.6
â€¢ 200 words â†’ 1.0
â€¢ 800 words â†’ 0.7 (penalty)
```

### C. Coherence - Cáº¥u trÃºc cÃ¢u
```
â€¢ Avg sentence length: 10-25 words = good
â€¢ Variance: Äa dáº¡ng Ä‘á»™ dÃ i cÃ¢u = good

Example:
Lengths: [15, 12, 20, 18, 14] â†’ avg=15.8, std=3.2 â†’ score = 0.9 âœ…
Lengths: [5, 5, 5, 5, 5]     â†’ avg=5, std=0    â†’ score = 0.3 âŒ
```

---

## 4. Faithfulness (0-1)

### Äo lÆ°á»ng: Answer cÃ³ dá»±a trÃªn context hay hallucination?

**CÃ´ng thá»©c (2 thÃ nh pháº§n):**
```
faithfulness = 0.7 Ã— token_grounding + 0.3 Ã— entity_grounding
```

### A. Token Grounding (70%)
```
Bao nhiÃªu % tokens trong answer xuáº¥t hiá»‡n trong context?

grounded_tokens = answer_tokens âˆ© context_tokens
token_grounding = grounded_tokens / answer_tokens

Example:
Answer:  "Adult males need 1g protein per kg"
Context: "Recommended protein for adult males is 1 gram per kilogram..."
Grounded: {Adult, males, need, 1g, protein, per, kg} = 7/7 = 1.0 âœ…
```

### B. Entity Grounding (30%)
```
Named entities trong answer cÃ³ trong context khÃ´ng?

Answer entities: ["Vitamin D", "Calcium", "Adult Males"]
Context mentions: ["Vitamin D", "Calcium"]  (chá»‰ 2/3)
entity_grounding = 2/3 = 0.67

Final: 0.7 Ã— 1.0 + 0.3 Ã— 0.67 = 0.90
```

---

## Overall Score

```
overall = (relevance + coverage + quality + faithfulness) / 4
```

---

## So sÃ¡nh thá»±c táº¿

### Query: "What supplements are recommended for males?"

| Metric | Trad RAG | Local | Global | Giáº£i thÃ­ch |
|--------|----------|-------|--------|------------|
| Relevance | 0.72 | 0.78 | 0.76 | Local tá»‘t nháº¥t (nhiá»u chunks liÃªn quan) |
| **Coverage** | **0.28** | **0.45** | **0.63** | **Global tháº¯ng (nhiá»u entities!)** |
| Quality | 0.68 | 0.70 | 0.72 | TÆ°Æ¡ng Ä‘Æ°Æ¡ng (cÃ¹ng LLM) |
| Faithfulness | 0.81 | 0.84 | 0.79 | RAG/Local cao (specific context) |
| **Overall** | **0.62** | **0.69** | **0.73** | **Global tháº¯ng nhá» coverage** |

---

## Khi nÃ o dÃ¹ng system nÃ o?

### Traditional RAG
âœ… **Tá»‘t khi:**
- Cáº§n exact information (facts, numbers, dates)
- Cáº§n citations tá»« specific sources
- Domain háº¹p, khÃ´ng cáº§n reasoning

âŒ **Yáº¿u khi:**
- Query phá»©c táº¡p, cáº§n multi-hop reasoning
- Cáº§n overview broad topics

**Example:** "What is the exact protein recommendation?"

### GraphRAG Local
âœ… **Tá»‘t khi:**
- Query cáº§n multi-hop reasoning (A â†’ B â†’ C)
- Cáº§n information tá»« related entities
- Query vá» relationships

âŒ **Yáº¿u khi:**
- Chá»‰ cáº§n simple fact lookup
- Coverage khÃ´ng quan trá»ng

**Example:** "How do protein, age, and exercise relate?"

### GraphRAG Global
âœ… **Tá»‘t khi:**
- High-level overview/themes
- Broad perspective across topics
- Summarization tasks

âŒ **Yáº¿u khi:**
- Cáº§n specific details
- Cáº§n exact quotes/citations

**Example:** "What are the main health considerations for males?"

---

## Táº¡i sao Coverage bá»‹ "stuck" á»Ÿ 0.1 trÆ°á»›c Ä‘Ã¢y?

### Root Cause:
```python
# Traditional RAG results:
{
    'content': 'text...',
    'score': 0.85,
    'type': 'chunk'
    # âŒ KHÃ”NG cÃ³ 'metadata.entities'
}

# Coverage = 0.4Ã—0.0 + 0.3Ã—0.6 + 0.3Ã—0.33 = 0.28
#            ^^^^^^
#            entity_diversity = 0 vÃ¬ khÃ´ng cÃ³ entities!
```

### Fix:
```python
# GraphRAG Global results BÃ‚Y GIá»œ cÃ³:
{
    'content': 'summary...',
    'score': 0.90,
    'type': 'community',
    'metadata': {
        'entities': ['body weight', 'adult males', 'protein'],  # âœ…
        'name': 'body weight'
    }
}

# Coverage = 0.4Ã—0.8 + 0.3Ã—0.7 + 0.3Ã—0.33 = 0.64 âœ…
#            ^^^^^^
#            entity_diversity = 0.8 tá»« entities!
```

---

## Káº¿t luáº­n

### 4 metrics = 4 khÃ­a cáº¡nh khÃ¡c nhau:

1. **Relevance** â†’ Retrieval Ä‘Ãºng khÃ´ng?
2. **Coverage** â†’ Information Ä‘a dáº¡ng khÃ´ng? (â­ GraphRAG tháº¯ng á»Ÿ Ä‘Ã¢y)
3. **Quality** â†’ Answer hay khÃ´ng?
4. **Faithfulness** â†’ Answer trung thá»±c khÃ´ng?

### Táº¡i sao GraphRAG Global thÆ°á»ng cÃ³ Overall Score cao nháº¥t?

**LÃ½ do:** **Coverage chiáº¿m 25% overall score, vÃ  GraphRAG Global cÃ³ coverage gáº¥p 2-3 láº§n RAG** nhá»:
- 40% weight tá»« entity_diversity
- Extract entities tá»« community titles
- Diverse topics trong communities

### KhÃ´ng cÃ³ system nÃ o "tá»‘t nháº¥t" cho má»i trÆ°á»ng há»£p!

- **Simple queries** â†’ Traditional RAG nhanh vÃ  accurate
- **Complex queries** â†’ GraphRAG Local vá»›i reasoning
- **Broad questions** â†’ GraphRAG Global vá»›i coverage

**Chá»n system phÃ¹ há»£p vá»›i use case cá»§a báº¡n!** ğŸ¯
